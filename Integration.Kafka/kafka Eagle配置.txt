创建日期：2023/02/07
作者：Osborn

系统：Windows10
Kafka Eagle版本：3.0.1
JAVA版本：17.0.1

Kafka Eagle下载地址：
http://www.kafka-eagle.org/

解压文件：
建文件夹->下载文件挪到新建的文件夹=>在该文件下打开powershell 输入tar -zxvf 文件全名->解压后依旧是一个新的gz文件，再次在解压后文件页面打开powershell重复tar步骤就可以了

！！！！！！！！！！！解压文件名不能存在空格，否则服务启动时读取环境变量地址只读取空格前面部分导致无法找到完全地址

配置环境变量：

系统变量+
1.JAVA_HOME:JDK解压地址
2.KE_HOME:KAFKA EAGLE解压地址

系统变量的Path变量+
1.%JAVA_HOME%\bin
2.%KE_HOME%\bin            


文件修改（解压地址\conf\system-config.properties）：

######################################
# multi zookeeper & kafka cluster list
# Settings prefixed with 'kafka.eagle.' will be deprecated, use 'efak.' instead
######################################
efak.zk.cluster.alias=cluster1
cluster1.zk.list=localhost:2181
# cluster2.zk.list=xdn10:2181,xdn11:2181,xdn12:2181

######################################
# zookeeper enable acl
######################################
cluster1.zk.acl.enable=false
cluster1.zk.acl.schema=digest
cluster1.zk.acl.username=test
cluster1.zk.acl.password=test123

######################################
# broker size online list
######################################
cluster1.efak.broker.size=20

######################################
# zk client thread limit
######################################
kafka.zk.limit.size=16

######################################
# EFAK webui port
# 端口改了也没用
######################################
efak.webui.port=8048

######################################
# EFAK enable distributed
######################################
efak.distributed.enable=false
efak.cluster.mode.status=master
efak.worknode.master.host=localhost
efak.worknode.port=8085

######################################
# kafka jmx acl and ssl authenticate
######################################
cluster1.efak.jmx.acl=false
cluster1.efak.jmx.user=keadmin
cluster1.efak.jmx.password=keadmin123
cluster1.efak.jmx.ssl=false
cluster1.efak.jmx.truststore.location=/data/ssl/certificates/kafka.truststore
cluster1.efak.jmx.truststore.password=ke123456

######################################
# kafka offset storage
######################################
cluster1.efak.offset.storage=kafka
# cluster2.efak.offset.storage=zk

######################################
# kafka jmx uri
######################################
cluster1.efak.jmx.uri=service:jmx:rmi:///jndi/rmi://%s/jmxrmi

######################################
# kafka metrics, 15 days by default
######################################
efak.metrics.charts=true
efak.metrics.retain=15

######################################
# kafka sql topic records max
######################################
efak.sql.topic.records.max=5000
efak.sql.topic.preview.records.max=10

######################################
# delete kafka topic token
######################################
efak.topic.token=keadmin

######################################
# kafka sasl authenticate
######################################
cluster1.efak.sasl.enable=false
cluster1.efak.sasl.protocol=SASL_PLAINTEXT
cluster1.efak.sasl.mechanism=PLAIN
cluster1.efak.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="kafka" password="kafka-eagle";
cluster1.efak.sasl.client.id=
cluster1.efak.blacklist.topics=
kafka.eagle.sasl.client=解压地址/conf/kafka_client_jaas.conf
# cluster1.efak.sasl.cgroup.enable=false
# cluster1.efak.sasl.cgroup.topics=
# cluster2.efak.sasl.enable=false
# cluster2.efak.sasl.protocol=SASL_PLAINTEXT
# cluster2.efak.sasl.mechanism=PLAIN
# cluster2.efak.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="kafka" password="kafka-eagle";
# cluster2.efak.sasl.client.id=
# cluster2.efak.blacklist.topics=
# cluster2.efak.sasl.cgroup.enable=false
# cluster2.efak.sasl.cgroup.topics=

######################################
# kafka ssl authenticate
######################################
cluster3.efak.ssl.enable=false
cluster3.efak.ssl.protocol=SSL
cluster3.efak.ssl.truststore.location=
cluster3.efak.ssl.truststore.password=
cluster3.efak.ssl.keystore.location=
cluster3.efak.ssl.keystore.password=
cluster3.efak.ssl.key.password=
cluster3.efak.ssl.endpoint.identification.algorithm=https
cluster3.efak.blacklist.topics=
cluster3.efak.ssl.cgroup.enable=false
cluster3.efak.ssl.cgroup.topics=

######################################
# kafka sqlite jdbc driver address
######################################
#efak.driver=org.sqlite.JDBC
#efak.url=jdbc:sqlite:/hadoop/kafka-eagle/db/ke.db
#efak.username=root
#efak.password=www.kafka-eagle.org

######################################
# kafka mysql jdbc driver address
#注意MySQL创建数据库(例:ke)，以及时区
#set global time_zone ='+8:00';设置中国时区
#flush privileges;立即生效
#show variables like "%time_zone%";查询时区
#也可使用sql lite自行查找
######################################
efak.driver=com.mysql.cj.jdbc.Driver
efak.url=jdbc:mysql://数据库地址:数据库端口/数据库名称（例:ke）?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull&serverTimezone=Asia/Shanghai
efak.username=登录mysql账号
efak.password=登录mysql密码

开启kafka JMX监控：
kafka解压路径\bin\kafka-server-start.sh 文件修改
if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms128M"
    export JMX_PORT="9999"（<-需要加这一句）


启动：
先启动 zookeeper，kafka
然后启动 解压地址\bin 下cmd 输入ke.bat


浏览器输入地址：
http://localhost:8048/
账号：admin
密码：123456



